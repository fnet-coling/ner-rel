{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "from data.load_fb15k237 import load_fb15k, load_fb15k_type_constraints, split_relations\n",
    "from sampler import *\n",
    "from eval import eval_triples\n",
    "from model import *\n",
    "from model.comp_models import *\n",
    "import sys\n",
    "from kb import subsample_kb\n",
    "import shutil\n",
    "import json\n",
    "from tensorflow.models.rnn.rnn_cell import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('fb15k_dir', \"data_rel\", 'data dir containing extracted files of fb15k dataset.')\n",
    "\n",
    "# model\n",
    "tf.app.flags.DEFINE_integer(\"size\", 50, \"hidden size of model\")\n",
    "\n",
    "# training\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 1e-2, \"Learning rate.\")\n",
    "tf.app.flags.DEFINE_float(\"l2_lambda\", 0, \"L2-regularization raten (only for batch training).\")\n",
    "tf.app.flags.DEFINE_float(\"sample_text_prob\", 0.935,\n",
    "                          \"Probability of sampling text triple (default is ratio of text (emnlp) to kb triples.\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate_decay\", 0.5, \"Learning rate decay when loss on validation set does not improve.\")\n",
    "tf.app.flags.DEFINE_integer(\"num_neg\", 200, \"Number of negative examples for training.\")\n",
    "tf.app.flags.DEFINE_integer(\"pos_per_batch\", 100, \"Number of examples in each batch for training.\")\n",
    "tf.app.flags.DEFINE_integer(\"max_iterations\", -1, \"Maximum number of batches during training. -1 means until convergence\")\n",
    "tf.app.flags.DEFINE_integer(\"ckpt_its\", -1, \"Number of iterations until running checkpoint. Negative means after every epoch.\")\n",
    "tf.app.flags.DEFINE_integer(\"random_seed\", 1234, \"Seed for rng.\")\n",
    "tf.app.flags.DEFINE_integer(\"subsample_kb\", -1, \"num of entities in subsampled kb. if <= 0 use whole kb\")\n",
    "tf.app.flags.DEFINE_boolean(\"kb_only\", True, \"Only load and train on FB relations, ignoring text.\")\n",
    "tf.app.flags.DEFINE_boolean(\"batch_train\", False, \"Use batch training.\")\n",
    "tf.app.flags.DEFINE_boolean(\"type_constraint\", False, \"Use type constraint during sampling.\")\n",
    "tf.app.flags.DEFINE_string(\"save_dir\", \"save/\" + time.strftime(\"%d%m%Y_%H%M%S\", time.localtime()),\n",
    "                           \"Where to save model and its configuration, always last will be kept.\")\n",
    "tf.app.flags.DEFINE_string(\"model\", \"DistMult\",\n",
    "                           \"Model architecture or combination thereof split by comma of: \"\n",
    "                           \"'ModelF', 'DistMult', 'ModelE', 'ModelO', 'ModelN', 'WeightedModelO'\")\n",
    "tf.app.flags.DEFINE_string(\"observed_sets\", \"train_text\", \"Which sets to observe for observed models.\")\n",
    "tf.app.flags.DEFINE_string(\"valid_mode\", \"a\", \"[a,t,nt] are possible. a- validate on all triples, \"\n",
    "                                              \"t- validate only on triples with text mentions, \"\n",
    "                                              \"nt- validate only on triples without text mentions\")\n",
    "tf.app.flags.DEFINE_string(\"composition\", None, \"'LSTM', 'GRU', 'RNN', 'BoW', 'BiLSTM', 'BiGRU', 'BiRNN'\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "if \",\" in FLAGS.model: #multiple model\n",
    "    FLAGS.model = FLAGS.model.split(\",\")\n",
    "\n",
    "FLAGS.observed_sets = FLAGS.observed_sets.split(\",\")\n",
    "\n",
    "assert (not FLAGS.batch_train or FLAGS.ckpt_its <= -1), \"Do not define checkpoint iterations when doing batch training.\"\n",
    "\n",
    "if FLAGS.batch_train:\n",
    "    print(\"Batch training!\")\n",
    "\n",
    "random.seed(FLAGS.random_seed)\n",
    "tf.set_random_seed(FLAGS.random_seed)\n",
    "\n",
    "kb = load_fb15k(FLAGS.fb15k_dir, with_text=not FLAGS.kb_only)\n",
    "if FLAGS.subsample_kb > 0:\n",
    "    kb = subsample_kb(kb, FLAGS.subsample_kb)\n",
    "\n",
    "if FLAGS.type_constraint:\n",
    "    print(\"Loading type constraints...\")\n",
    "    load_fb15k_type_constraints(kb, os.path.join(FLAGS.fb15k_dir, \"types\"))\n",
    "\n",
    "num_kb = 0\n",
    "num_text = 0\n",
    "\n",
    "for f in kb.get_all_facts():\n",
    "    if f[2] == \"train\":\n",
    "        num_kb += 1\n",
    "    elif f[2] == \"train_text\":\n",
    "        num_text += 1\n",
    "print(\"Loaded data. %d kb triples. %d text_triples.\" % (num_kb, num_text))\n",
    "batch_size = (FLAGS.num_neg+1) * FLAGS.pos_per_batch * 2  # x2 because subject and object loss training\n",
    "#random sampler for generating negative samples\n",
    "fact_sampler = BatchNegTypeSampler(kb, FLAGS.pos_per_batch, which_set=\"train\", neg_per_pos=FLAGS.num_neg, type_constraint=FLAGS.type_constraint)\n",
    "\n",
    "if not FLAGS.kb_only:\n",
    "    text_sampler = BatchNegTypeSampler(kb, FLAGS.pos_per_batch, which_set=\"train_text\", neg_per_pos=FLAGS.num_neg, type_constraint=False)\n",
    "print(\"Created Samplers.\")\n",
    "train_dir = os.path.join(FLAGS.save_dir, \"train\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "subsample_validation = map(lambda x: x[0], kb.get_all_facts_of_arity(2, \"valid\"))\n",
    "if len(subsample_validation) > 5000:\n",
    "    subsample_validation = random.sample(subsample_validation, 5000)\n",
    "\n",
    "\n",
    "if FLAGS.ckpt_its <= 0:\n",
    "    print \"Setting checkpoint iteration to size of whole epoch.\"\n",
    "    FLAGS.ckpt_its = fact_sampler.epoch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print \"Creating model ...\"\n",
    "    model = create_model(kb, FLAGS.size, batch_size, num_neg=FLAGS.num_neg, learning_rate=FLAGS.learning_rate,\n",
    "                         l2_lambda=FLAGS.l2_lambda, is_batch_training=FLAGS.batch_train, type=FLAGS.model,\n",
    "                         observed_sets=FLAGS.observed_sets, composition=FLAGS.composition)#create a model object\n",
    "\n",
    "    print \"Created model: \" + model.name()\n",
    "\n",
    "    if os.path.exists(train_dir) and any(\"ckpt\" in x for x in os.listdir(train_dir)):\n",
    "        newest = max(map(lambda x: os.path.join(train_dir, x),\n",
    "                         filter(lambda x: \".ckpt\" in x, os.listdir(train_dir))), key=os.path.getctime)\n",
    "        print \"Loading from checkpoint \" + newest\n",
    "        model.saver.restore(sess, newest)\n",
    "    else:\n",
    "        if not os.path.exists(train_dir):\n",
    "            os.makedirs(train_dir)\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    num_params = reduce(lambda acc, x: acc + x.size, sess.run(tf.trainable_variables()), 0)\n",
    "    print(\"Num params: %d\" % num_params)\n",
    "    print(\"Initialized model.\")\n",
    "    loss = 0.0\n",
    "    step_time = 0.0\n",
    "    previous_mrrs = list()\n",
    "    mrr2modelpath = dict()\n",
    "    e = 0\n",
    "    mode = \"update\"\n",
    "    if FLAGS.batch_train:\n",
    "        mode = \"accumulate\"\n",
    "\n",
    "    checkpoint_path = os.path.join(train_dir, \"model.ckpt\")\n",
    "    end_of_epoch = False\n",
    "    def sample_next_batch():\n",
    "        if FLAGS.kb_only or random.random() >= FLAGS.sample_text_prob:\n",
    "            return fact_sampler.get_batch_async()\n",
    "        else:\n",
    "            return text_sampler.get_batch_async()\n",
    "\n",
    "    next_batch = sample_next_batch()\n",
    "\n",
    "    while FLAGS.max_iterations < 0 or i < FLAGS.max_iterations:\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        pos, negs = next_batch.get()\n",
    "        end_of_epoch = fact_sampler.end_of_epoch()\n",
    "        current_ct = fact_sampler.count\n",
    "        # already fetch next batch parallel to running model\n",
    "        next_batch = sample_next_batch()\n",
    "\n",
    "        loss += model.step(sess, pos, negs, mode)\n",
    "        step_time += (time.time() - start_time)\n",
    "\n",
    "        sys.stdout.write(\"\\r%.1f%% Loss: %.3f\" %\n",
    "                         (float((i-1) % FLAGS.ckpt_its + 1.0)*100.0 / FLAGS.ckpt_its,\n",
    "                          loss / float((i-1) % FLAGS.ckpt_its + 1.0)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if end_of_epoch and not fact_sampler.end_of_epoch():\n",
    "            print \"\"\n",
    "            e += 1\n",
    "            print \"Epoch %d done!\" % e\n",
    "            if FLAGS.batch_train:\n",
    "                loss_without_l2 = sess.run(model._loss) / FLAGS.pos_per_batch / FLAGS.ckpt_its / 2\n",
    "                print \"Per example loss without L2 %.3f\" % loss_without_l2\n",
    "                model.acc_l2_gradients(sess)\n",
    "                loss = model.update(sess)\n",
    "                model.reset_gradients_and_loss(sess)\n",
    "\n",
    "        if (end_of_epoch and not fact_sampler.end_of_epoch() and FLAGS.batch_train) or (not FLAGS.batch_train and i % FLAGS.ckpt_its == 0):\n",
    "            if not FLAGS.batch_train:\n",
    "                loss /= FLAGS.ckpt_its\n",
    "                print \"\"\n",
    "                print \"%d%% in epoch done.\" % (100*current_ct/fact_sampler.epoch_size)\n",
    "            # Print statistics for the previous epoch.\n",
    "            step_time /= FLAGS.ckpt_its\n",
    "            print \"global step %d learning rate %.4f, step-time %.3f, loss %.4f\" % (model.global_step.eval(),\n",
    "                                                                                    model.learning_rate.eval(),\n",
    "                                                                                    step_time, loss)\n",
    "            step_time, loss = 0.0, 0.0\n",
    "            valid_loss = 0.0\n",
    "\n",
    "            # Run evals on development set and print their perplexity.\n",
    "            print \"########## Validation ##############\"\n",
    "            (mrr_a, _), (mrr_t, _), (mrr_nt, _) = eval_triples(sess, kb, model, subsample_validation, verbose=True)\n",
    "\n",
    "            if FLAGS.valid_mode == \"a\":\n",
    "                mrr = mrr_a\n",
    "            elif FLAGS.valid_mode == \"t\":\n",
    "                mrr = mrr_t\n",
    "            elif FLAGS.valid_mode == \"nt\":\n",
    "                mrr = mrr_nt\n",
    "            else:\n",
    "                raise ValueError(\"valid_mode flag must be either 'a','t' or 'nt'\")\n",
    "\n",
    "            if e >= 1 and len(previous_mrrs) > 2 and mrr <= min(previous_mrrs[-2:])+1e-4:\n",
    "                print \"Stop learning!\"\n",
    "                break\n",
    "                #lr = model.learning_rate.eval()\n",
    "                #sess.run(model.learning_rate.assign(lr * FLAGS.learning_rate_decay))\n",
    "                #print \"Decaying learning rate to: %.4f\" % model.learning_rate.eval()\n",
    "\n",
    "            previous_mrrs.append(mrr)\n",
    "            # Save checkpoint and zero timer and loss.\n",
    "            path = model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "            mrr2modelpath[mrr] = path\n",
    "            print \"####################################\"\n",
    "\n",
    "    best_valid_mrr = max(previous_mrrs[-5:])\n",
    "    print(\"Restore model to best on validation, with MRR: %.3f\" % best_valid_mrr)\n",
    "    model.saver.restore(sess, mrr2modelpath[best_valid_mrr])\n",
    "    model_name = mrr2modelpath[best_valid_mrr].split(\"/\")[-1]\n",
    "    shutil.copyfile(mrr2modelpath[best_valid_mrr], os.path.join(FLAGS.save_dir, model_name))\n",
    "    print \"########## Test ##############\"\n",
    "    (mrr, top10), (mrr_wt, top10_wt), (mrr_nt, top10_nt) = eval_triples(sess, kb, model, map(lambda x: x[0], kb.get_all_facts_of_arity(2, \"test\")), verbose=True)\n",
    "    with open(os.path.join(FLAGS.save_dir, \"result.txt\"), 'w') as f:\n",
    "        f.write(\"best model: %s\\n\\nMRR: %.3f\\nHits10: %.3f\\n\\n\" % (model_name, mrr, top10))\n",
    "        f.write(\"MRR wt: %.3f\\nHits10 wt: %.3f\\n\\n\" % (mrr_wt, top10_wt))\n",
    "        f.write(\"MRR nt: %.3f\\nHits10 nt: %.3f\\n\\nFLAGS:\\n\" % (mrr_nt, top10_nt))\n",
    "        f.write(json.dumps(FLAGS.__flags, sort_keys=True, indent=2, separators=(',', ': ')))\n",
    "        f.flush()\n",
    "    print \"##############################\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()\n",
    "print \"Creating model ...\"\n",
    "model = create_model(kb, FLAGS.size, batch_size, num_neg=FLAGS.num_neg, learning_rate=FLAGS.learning_rate,\n",
    "                     l2_lambda=FLAGS.l2_lambda, is_batch_training=FLAGS.batch_train, type=FLAGS.model,\n",
    "                     observed_sets=FLAGS.observed_sets, composition=FLAGS.composition)#create a model object\n",
    "model.saver.restore(sess,\"/Users/mayk/working/rel_extractor/baseline/genie-kb/save/28042016_152904/model.ckpt-2160\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(mrr, top10), (mrr_wt, top10_wt), (mrr_nt, top10_nt) = eval_triples(sess, kb, model, map(lambda x: x[0], kb.get_all_facts_of_arity(2, \"test\")), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[2, 2])\n",
    "y = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "z = tf.matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(mrr, top10), (mrr_wt, top10_wt), (mrr_nt, top10_nt) = eval_triples(sess, kb, model, map(lambda x: x[0], kb.get_all_facts_of_arity(2, \"test\")), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sha = sess.run([b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model._kb.get_id('->conj_and->',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=kb.get_all_facts_of_arity(2, \"test\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = tf.mul(a,model.e_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(model.e_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(\"float\", 3)\n",
    "y = x * 2\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(y, feed_dict={x: [1, 2, 3]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "            E_subjs = tf.get_variable(\"E_s\", [len(model._kb.get_symbols(1)), model._size])\n",
    "            E_objs = tf.get_variable(\"E_o\", [len(model._kb.get_symbols(2)), model._size])\n",
    "            E_rels = tf.get_variable(\"E_r\", [len(model._kb.get_symbols(0)), model._size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model..eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_obj= sess.run(model.e_obj,feed_dict={model._obj_input:np.array(range(len(model._kb.get_vocab(1))))})\n",
    "e_subj= sess.run(model.e_subj,feed_dict={model._subj_input:np.array(range(len(model._kb.get_vocab(2))))})\n",
    "e_rel= sess.run(model.e_rel,feed_dict={model._rel_input:np.array(range(len(model._kb.get_vocab(0))))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_obj==e_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rid = dict([(v,k)for k,v in enumerate(model._kb.get_vocab(0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in enumerate(model._kb.get_vocab(0)):print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lid = dict([(k,v)for k,v in enumerate(model._kb.get_vocab(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in enumerate(model._kb.get_vocab(2)):print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best(rel,e_rel,e_lbl,rid,lid):\n",
    "    vec_r = e_rel[rid[rel]]\n",
    "    min_so = []\n",
    "    min_dist = -1000\n",
    "    for i in range(len(e_rel)):\n",
    "        vec_s = e_rel[i]\n",
    "        for j in range(len(e_rel)):\n",
    "            if j!=i:\n",
    "                vec_o = e_rel[j]\n",
    "                dist = np.dot(vec_r,(vec_s*vec_o))\n",
    "                if dist>=min_dist:\n",
    "                    min_so = [lid[i],lid[j],min_dist]\n",
    "                    min_dist = dist\n",
    "                    \n",
    "    return min_so\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/SUBSTANCE/FOOD', '/PLANT', 10.065162]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best('->prep_near->',e_rel,e_subj,rid,lid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
