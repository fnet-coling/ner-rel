{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "from data.load_fb15k237 import load_fb15k, load_fb15k_type_constraints, split_relations\n",
    "from sampler import *\n",
    "from eval import eval_triples\n",
    "from model import *\n",
    "from model.comp_models import *\n",
    "import sys\n",
    "from kb import subsample_kb\n",
    "import shutil\n",
    "import json\n",
    "from tensorflow.models.rnn.rnn_cell import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data. 13563 kb triples. 66301 text_triples.\n",
      "Created Samplers.\n",
      "Setting checkpoint iteration to size of whole epoch.\n",
      "Creating model ...\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('fb15k_dir', \"data_rel\", 'data dir containing extracted files of fb15k dataset.')\n",
    "\n",
    "# model\n",
    "tf.app.flags.DEFINE_integer(\"size\", 50, \"hidden size of model\")\n",
    "\n",
    "# training\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 1e-2, \"Learning rate.\")\n",
    "tf.app.flags.DEFINE_float(\"l2_lambda\", 0, \"L2-regularization raten (only for batch training).\")\n",
    "tf.app.flags.DEFINE_float(\"sample_text_prob\", 0.935,\n",
    "                          \"Probability of sampling text triple (default is ratio of text (emnlp) to kb triples.\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate_decay\", 0.5, \"Learning rate decay when loss on validation set does not improve.\")\n",
    "tf.app.flags.DEFINE_integer(\"num_neg\", 200, \"Number of negative examples for training.\")\n",
    "tf.app.flags.DEFINE_integer(\"pos_per_batch\", 100, \"Number of examples in each batch for training.\")\n",
    "tf.app.flags.DEFINE_integer(\"max_iterations\", -1, \"Maximum number of batches during training. -1 means until convergence\")\n",
    "tf.app.flags.DEFINE_integer(\"ckpt_its\", -1, \"Number of iterations until running checkpoint. Negative means after every epoch.\")\n",
    "tf.app.flags.DEFINE_integer(\"random_seed\", 1234, \"Seed for rng.\")\n",
    "tf.app.flags.DEFINE_integer(\"subsample_kb\", -1, \"num of entities in subsampled kb. if <= 0 use whole kb\")\n",
    "tf.app.flags.DEFINE_boolean(\"kb_only\", False, \"Only load and train on FB relations, ignoring text.\")\n",
    "tf.app.flags.DEFINE_boolean(\"batch_train\", False, \"Use batch training.\")\n",
    "tf.app.flags.DEFINE_boolean(\"type_constraint\", False, \"Use type constraint during sampling.\")\n",
    "tf.app.flags.DEFINE_string(\"save_dir\", \"save/\" + time.strftime(\"%d%m%Y_%H%M%S\", time.localtime()),\n",
    "                           \"Where to save model and its configuration, always last will be kept.\")\n",
    "tf.app.flags.DEFINE_string(\"model\", \"DistMult\",\n",
    "                           \"Model architecture or combination thereof split by comma of: \"\n",
    "                           \"'DistMult', 'DistMult', 'ModelE', 'ModelO', 'ModelN', 'WeightedModelO'\")\n",
    "tf.app.flags.DEFINE_string(\"observed_sets\", \"train_text\", \"Which sets to observe for observed models.\")\n",
    "tf.app.flags.DEFINE_string(\"valid_mode\", \"a\", \"[a,t,nt] are possible. a- validate on all triples, \"\n",
    "                                              \"t- validate only on triples with text mentions, \"\n",
    "                                              \"nt- validate only on triples without text mentions\")\n",
    "tf.app.flags.DEFINE_string(\"composition\", \"BiRNN\", \"'LSTM', 'GRU', 'RNN', 'BoW', 'BiLSTM', 'BiGRU', 'BiRNN'\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "if \",\" in FLAGS.model: #multiple model\n",
    "    FLAGS.model = FLAGS.model.split(\",\")\n",
    "\n",
    "FLAGS.observed_sets = FLAGS.observed_sets.split(\",\")\n",
    "\n",
    "assert (not FLAGS.batch_train or FLAGS.ckpt_its <= -1), \"Do not define checkpoint iterations when doing batch training.\"\n",
    "\n",
    "if FLAGS.batch_train:\n",
    "    print(\"Batch training!\")\n",
    "\n",
    "random.seed(FLAGS.random_seed)\n",
    "tf.set_random_seed(FLAGS.random_seed)\n",
    "\n",
    "kb = load_fb15k(FLAGS.fb15k_dir, with_text=not FLAGS.kb_only)\n",
    "if FLAGS.subsample_kb > 0:\n",
    "    kb = subsample_kb(kb, FLAGS.subsample_kb)\n",
    "\n",
    "if FLAGS.type_constraint:\n",
    "    print(\"Loading type constraints...\")\n",
    "    load_fb15k_type_constraints(kb, os.path.join(FLAGS.fb15k_dir, \"types\"))\n",
    "\n",
    "num_kb = 0\n",
    "num_text = 0\n",
    "\n",
    "for f in kb.get_all_facts():\n",
    "    if f[2] == \"train\":\n",
    "        num_kb += 1\n",
    "    elif f[2] == \"train_text\":\n",
    "        num_text += 1\n",
    "print(\"Loaded data. %d kb triples. %d text_triples.\" % (num_kb, num_text))\n",
    "batch_size = (FLAGS.num_neg+1) * FLAGS.pos_per_batch * 2  # x2 because subject and object loss training\n",
    "#random sampler for generating negative samples\n",
    "fact_sampler = BatchNegTypeSampler(kb, FLAGS.pos_per_batch, which_set=\"train\", neg_per_pos=FLAGS.num_neg, type_constraint=FLAGS.type_constraint)\n",
    "\n",
    "if not FLAGS.kb_only:\n",
    "    text_sampler = BatchNegTypeSampler(kb, FLAGS.pos_per_batch, which_set=\"train_text\", neg_per_pos=FLAGS.num_neg, type_constraint=False)\n",
    "print(\"Created Samplers.\")\n",
    "train_dir = os.path.join(FLAGS.save_dir, \"train\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "subsample_validation = map(lambda x: x[0], kb.get_all_facts_of_arity(2, \"valid\"))\n",
    "if len(subsample_validation) > 5000:\n",
    "    subsample_validation = random.sample(subsample_validation, 5000)\n",
    "\n",
    "\n",
    "if FLAGS.ckpt_its <= 0:\n",
    "    print \"Setting checkpoint iteration to size of whole epoch.\"\n",
    "    FLAGS.ckpt_its = fact_sampler.epoch_size\n",
    "sess= tf.InteractiveSession()\n",
    "print \"Creating model ...\"\n",
    "model = create_model(kb, FLAGS.size, batch_size, num_neg=FLAGS.num_neg, learning_rate=FLAGS.learning_rate,\n",
    "                     l2_lambda=FLAGS.l2_lambda, is_batch_training=FLAGS.batch_train, type=FLAGS.model,\n",
    "                     observed_sets=FLAGS.observed_sets, composition=FLAGS.composition)#create a model object\n",
    "model.saver.restore(sess,\"/Users/mayk/working/rel_extractor/baseline/genie-kb/save/03052016_172546/train/model.ckpt-4641\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "shit ass\n"
     ]
    }
   ],
   "source": [
    "from gensim.matutils import argsort\n",
    "def query(rel,scores,tuples):\n",
    "    indices = [ i for i in range(len(tuples)) if tuples[i][0] == rel]\n",
    "    scores = scores[indices]\n",
    "    tuples = [tuples[id] for id in indices]\n",
    "    bests =argsort(scores,reverse=True)[:10]\n",
    "    return [(tuples[best],scores[best]) for best in bests]\n",
    "def make_tuples(rel,vocab):\n",
    "    return [(rel,e1,e2) for e1 in vocab for e2 in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('[XXX]:<conj>:and:[YYY]', '/EVENT', '/CONTACT_INFO/url'),\n",
       "  6.7448163032531738),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION', '/LOCATION'),\n",
       "  6.7448163032531738),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/CORPORATION', '/LOCATION'),\n",
       "  6.5021052360534668),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/EVENT', '/CONTACT_INFO'), 6.5021052360534668),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/WORK_OF_ART', '/EVENT'), 6.0701150894165039),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/GOVERNMENT', '/LOCATION'),\n",
       "  5.8778252601623535),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/EVENT', '/LOCATION/REGION'),\n",
       "  5.8778252601623535),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/FACILITY/ATTRACTION', '/CONTACT_INFO/url'),\n",
       "  5.7633728981018066),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION', '/GPE'), 5.7633728981018066),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/GOVERNMENT', '/GPE'),\n",
       "  5.4421877861022949)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= '[XXX]:<conj>:and:[YYY]'\n",
    "tuples = make_tuples(q,model._kb.get_vocab(1))\n",
    "scores = model.score_triples(sess,tuples)\n",
    "query(q,scores,tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('[XXX]:<conj>:and:[YYY]', '/EVENT', '/CONTACT_INFO/url'),\n",
       "  6.7448163032531738),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION', '/LOCATION'),\n",
       "  6.7448163032531738),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/CORPORATION', '/LOCATION'),\n",
       "  6.5021052360534668),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/EVENT', '/CONTACT_INFO'), 6.5021052360534668),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/WORK_OF_ART', '/EVENT'), 6.0701150894165039),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/GOVERNMENT', '/LOCATION'),\n",
       "  5.8778252601623535),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/EVENT', '/LOCATION/REGION'),\n",
       "  5.8778252601623535),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/FACILITY/ATTRACTION', '/CONTACT_INFO/url'),\n",
       "  5.7633728981018066),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION', '/GPE'), 5.7633728981018066),\n",
       " (('[XXX]:<conj>:and:[YYY]', '/ORGANIZATION/GOVERNMENT', '/GPE'),\n",
       "  5.4421877861022949)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= '[XXX]:<conj>:and:[YYY]'\n",
    "tuples = make_tuples(q,model._kb.get_vocab(1))\n",
    "scores = model.score_triples(sess,tuples)\n",
    "query(q,scores,tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing new boss\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "e_obj= sess.run(model.e_obj,feed_dict={model._obj_input:np.array(range(len(model._kb.get_vocab(1))))})\n",
    "with open('label.bin','wb') as f:\n",
    "    vocab  =list(model._kb.get_vocab(1))\n",
    "    f.write(\"160 50\\n\");\n",
    "    for i in range(len(vocab)):\n",
    "        f.write(\"%s %s\\n\" % (vocab[i],\" \".join(map(lambda x:str(x),e_obj[i]))))\n",
    "emb  = Word2Vec.load_word2vec_format('label.bin',binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/LANGUAGE', 0.6813899874687195),\n",
       " (u'/LOCATION/LAKE_SEA_OCEAN', 0.6801102161407471),\n",
       " (u'/WORK_OF_ART/SONG', 0.67412269115448),\n",
       " (u'/SUBSTANCE/DRUG', 0.6518536806106567),\n",
       " (u'/WORK_OF_ART/BOOK', 0.6446441411972046),\n",
       " (u'/CONTACT_INFO/url', 0.6431254744529724),\n",
       " (u'/FACILITY/BRIDGE', 0.6131840944290161),\n",
       " (u'/WORK_OF_ART', 0.6089992523193359),\n",
       " (u'/SUBSTANCE/CHEMICAL', 0.5996747612953186),\n",
       " (u'/FACILITY/HIGHWAY_STREET', 0.5766296982765198)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.most_similar(positive=['/CONTACT_INFO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'/ANIMAL': <gensim.models.word2vec.Vocab at 0x11943d6d0>,\n",
       " u'/CONTACT_INFO': <gensim.models.word2vec.Vocab at 0x11943d910>,\n",
       " u'/CONTACT_INFO/url': <gensim.models.word2vec.Vocab at 0x11943d8d0>,\n",
       " u'/DISEASE': <gensim.models.word2vec.Vocab at 0x11943d590>,\n",
       " u'/EVENT': <gensim.models.word2vec.Vocab at 0x11943d650>,\n",
       " u'/EVENT/HURRICANE': <gensim.models.word2vec.Vocab at 0x11943ddd0>,\n",
       " u'/EVENT/WAR': <gensim.models.word2vec.Vocab at 0x11943da90>,\n",
       " u'/FACILITY': <gensim.models.word2vec.Vocab at 0x11943d810>,\n",
       " u'/FACILITY/AIRPORT': <gensim.models.word2vec.Vocab at 0x11943df10>,\n",
       " u'/FACILITY/ATTRACTION': <gensim.models.word2vec.Vocab at 0x11943d850>,\n",
       " u'/FACILITY/BRIDGE': <gensim.models.word2vec.Vocab at 0x11943dd90>,\n",
       " u'/FACILITY/BUILDING': <gensim.models.word2vec.Vocab at 0x11943dc50>,\n",
       " u'/FACILITY/HIGHWAY_STREET': <gensim.models.word2vec.Vocab at 0x11943de90>,\n",
       " u'/GAME': <gensim.models.word2vec.Vocab at 0x11943db90>,\n",
       " u'/GPE': <gensim.models.word2vec.Vocab at 0x11943d610>,\n",
       " u'/GPE/CITY': <gensim.models.word2vec.Vocab at 0x11943d5d0>,\n",
       " u'/GPE/COUNTRY': <gensim.models.word2vec.Vocab at 0x11943d9d0>,\n",
       " u'/GPE/STATE_PROVINCE': <gensim.models.word2vec.Vocab at 0x11943d990>,\n",
       " u'/LANGUAGE': <gensim.models.word2vec.Vocab at 0x11943dd50>,\n",
       " u'/LAW': <gensim.models.word2vec.Vocab at 0x11943dd10>,\n",
       " u'/LOCATION': <gensim.models.word2vec.Vocab at 0x11943d510>,\n",
       " u'/LOCATION/CONTINENT': <gensim.models.word2vec.Vocab at 0x11943dc90>,\n",
       " u'/LOCATION/LAKE_SEA_OCEAN': <gensim.models.word2vec.Vocab at 0x11943df50>,\n",
       " u'/LOCATION/REGION': <gensim.models.word2vec.Vocab at 0x11943dcd0>,\n",
       " u'/LOCATION/RIVER': <gensim.models.word2vec.Vocab at 0x11943de10>,\n",
       " u'/ORGANIZATION': <gensim.models.word2vec.Vocab at 0x11943d750>,\n",
       " u'/ORGANIZATION/CORPORATION': <gensim.models.word2vec.Vocab at 0x11943d790>,\n",
       " u'/ORGANIZATION/EDUCATIONAL': <gensim.models.word2vec.Vocab at 0x11943dbd0>,\n",
       " u'/ORGANIZATION/GOVERNMENT': <gensim.models.word2vec.Vocab at 0x11943d7d0>,\n",
       " u'/ORGANIZATION/HOSPITAL': <gensim.models.word2vec.Vocab at 0x11943d710>,\n",
       " u'/ORGANIZATION/HOTEL': <gensim.models.word2vec.Vocab at 0x11943dfd0>,\n",
       " u'/ORGANIZATION/MUSEUM': <gensim.models.word2vec.Vocab at 0x11943dc10>,\n",
       " u'/ORGANIZATION/POLITICAL': <gensim.models.word2vec.Vocab at 0x11943da10>,\n",
       " u'/ORGANIZATION/RELIGIOUS': <gensim.models.word2vec.Vocab at 0x11943ded0>,\n",
       " u'/PERSON': <gensim.models.word2vec.Vocab at 0x11943d690>,\n",
       " u'/PLANT': <gensim.models.word2vec.Vocab at 0x117c6c290>,\n",
       " u'/PRODUCT': <gensim.models.word2vec.Vocab at 0x117c15f10>,\n",
       " u'/PRODUCT/VEHICLE': <gensim.models.word2vec.Vocab at 0x11943de50>,\n",
       " u'/PRODUCT/WEAPON': <gensim.models.word2vec.Vocab at 0x11943db10>,\n",
       " u'/SUBSTANCE': <gensim.models.word2vec.Vocab at 0x117bada50>,\n",
       " u'/SUBSTANCE/CHEMICAL': <gensim.models.word2vec.Vocab at 0x11943da50>,\n",
       " u'/SUBSTANCE/DRUG': <gensim.models.word2vec.Vocab at 0x11943dad0>,\n",
       " u'/SUBSTANCE/FOOD': <gensim.models.word2vec.Vocab at 0x11943d490>,\n",
       " u'/WORK_OF_ART': <gensim.models.word2vec.Vocab at 0x11943d890>,\n",
       " u'/WORK_OF_ART/BOOK': <gensim.models.word2vec.Vocab at 0x11943d950>,\n",
       " u'/WORK_OF_ART/PLAY': <gensim.models.word2vec.Vocab at 0x11943df90>,\n",
       " u'/WORK_OF_ART/SONG': <gensim.models.word2vec.Vocab at 0x11943db50>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.load_fb15k237 import split_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facts = [ fact[0][0] for fact in model._kb.get_all_facts() if fact[2] == 'train_text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in facts[:100]:\n",
    "    print f,split_relations(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9c9852428156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/GPE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emb' is not defined"
     ]
    }
   ],
   "source": [
    "emb.most_similar(positive=['/GPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(e_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
